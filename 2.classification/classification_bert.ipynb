{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic classification of stigmatizing mental illness articles in online news journals - April 2022\n",
    "Author: Alina Yanchuk - alinayanchuk@ua.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents:\n",
    "\n",
    "* [4. Classification](#chapter4)\n",
    "    * [4.1 Requirements](#section_4_1)\n",
    "    * [4.2 Imports](#section_4_2)\n",
    "    * [4.3 Get data](#section_4_3)\n",
    "    * [4.4 Train and Test dataset](#section_4_4)\n",
    "    * [4.5 Model training/fine-tuning](#section_4_5)\n",
    "    * [4.6 Evaluation analysis](#section_4_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification with BERT (BERTimbau) <a class=\"anchor\" id=\"chapter4\"></a>\n",
    "\n",
    "Most of the labeled text datasets are not big enough to train deep neural networks and get the most accurate results. Pre-trained models came to help. Transfer learning is a technique where a deep learning model trained on a large dataset is used to perform similar tasks on another dataset. The models are already pre-trained and just need to be fine-tuned for the specific task/problem. BERT is one example of these models.\n",
    "\n",
    "- BERT models are usually pre-trained on a large corpus of text, then fine-tuned for specific tasks;\n",
    "- BERT uses the Transformer encoder architecture to process each token of input text in the full context of all tokens before and after;\n",
    "- BERTimbau is trained on the Portuguese language. BERT-Base and BERT-Large Cased variants were trained on the BrWaC (Brazilian Web as Corpus), a large Portuguese corpus, for 1,000,000 steps, using whole-word mask.\n",
    "\n",
    "\n",
    "\n",
    "References:\n",
    "    1. https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification\n",
    "    2. https://github.com/neuralmind-ai/portuguese-bert\n",
    "    3. https://medium.com/swlh/a-simple-guide-on-using-bert-for-text-classification-bbf041ac8d04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Requirements <a class=\"anchor\" id=\"section_4_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Imports <a class=\"anchor\" id=\"section_3_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 19:27:46.234929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-31 19:27:46.235068: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch import optim, cuda\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support as scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Get data <a class=\"anchor\" id=\"section_4_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>prisão perpétua homem tentou assassinar senado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>john nash matemático mente brilhante morre aci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>mito reeleição mínima garantida cavaco sairá d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>morreu rita levintalcini grande dama ciência i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>trás porta amarela homem problemas psicológico...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content\n",
       "0      0  prisão perpétua homem tentou assassinar senado...\n",
       "1      0  john nash matemático mente brilhante morre aci...\n",
       "2      1  mito reeleição mínima garantida cavaco sairá d...\n",
       "3      0  morreu rita levintalcini grande dama ciência i...\n",
       "4      0  trás porta amarela homem problemas psicológico..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('data_preprocessed.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Train and Test dataset <a class=\"anchor\" id=\"section_4_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news in train dataset: 412\n",
      "Number of news in validation dataset: 104\n",
      "Number of news in test dataset: 129\n"
     ]
    }
   ],
   "source": [
    "# Divide the data et into a 80% train dataset and 20% test dataset\n",
    "# Divide the train dataset into a 80% train dataset and 20% validation dataset\n",
    "\n",
    "data = data.loc[:,['content', 'label']]\n",
    "\n",
    "data_train, data_test = train_test_split(data, train_size=0.8, random_state=55, stratify=data.label.values)\n",
    "data_train, data_val = train_test_split(data_train, random_state=55, train_size=0.8, stratify=data_train.label.values)\n",
    "\n",
    "train = [{'X': content, 'y': label} for (content, label) in zip(data_train.content, data_train.label)]\n",
    "test = [{'X': content, 'y': label} for (content, label) in zip(data_test.content, data_test.label)]\n",
    "val = [{'X': content, 'y': label} for (content, label) in zip(data_val.content, data_val.label)]\n",
    "\n",
    "print(\"Number of news in train dataset: \" + str(len(train)))\n",
    "print(\"Number of news in validation dataset: \" + str(len(val)))\n",
    "print(\"Number of news in test dataset: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Model training/fine-tuning <a class=\"anchor\" id=\"section_4_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set relevant parameters\n",
    "\n",
    "pretrained_model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "n_classes = 2 # Binary problem\n",
    "n_epochs = 4 \n",
    "batch_size = 8\n",
    "batch_status = 32\n",
    "learning_rate = 1e-5\n",
    "early_stop = 2 \n",
    "max_length = 480 # Pad or truncate all texts to same length\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'  # GPU or CPU\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data into batches of tensors\n",
    "\n",
    "traindata = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valdata = DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "testdata = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Get pre-trained model, it's tokenizer, an optimizer and scheduler.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name, do_lowercase=False)\n",
    "pretrained_model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=n_classes).to(device) # Bert Model transformer with a sequence classification head on top (a linear layer on top of the pooled output) \n",
    "\n",
    "optimizer = optim.AdamW(pretrained_model.parameters(), lr=learning_rate)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = n_epochs*len(traindata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the validation dataset\n",
    "\n",
    "def evaluate_val(model, valdata):\n",
    "  y_real, y_pred = [], []\n",
    "  losses = []\n",
    "\n",
    "  model.eval()\n",
    "  \n",
    "  for batch_idx, inp in enumerate(valdata):\n",
    "    texts, labels = inp['X'], inp['y']\n",
    "\n",
    "    with torch.no_grad():\n",
    "      # Classifying\n",
    "      inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device)\n",
    "      output = model(**inputs, labels=labels.to(device))\n",
    "                  \n",
    "      pred_labels = torch.argmax(output.logits, 1)\n",
    "\n",
    "      loss = output.loss\n",
    "      losses.append(float(loss.item()))\n",
    "      \n",
    "      y_real.extend(labels.tolist())\n",
    "      y_pred.extend(pred_labels.tolist())\n",
    "\n",
    "    if (batch_idx+1) % batch_status == 0:\n",
    "      print('Progress:', round(batch_idx / len(testdata), 2), batch_idx)\n",
    "\n",
    "  avg_loss = round(sum(losses) / len(losses), 5)\n",
    "  print(classification_report(y_real, y_pred, labels=[0, 1], target_names=['Literal', 'Stigma']))\n",
    "\n",
    "  return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store evaluation metrics for the final model testing\n",
    "\n",
    "def evaluate_test(model, testdata):\n",
    "  evaluation_metrics_list = []\n",
    "  y_real, y_pred = [], []\n",
    "\n",
    "  model.eval()\n",
    "  \n",
    "  for batch_idx, inp in enumerate(testdata):\n",
    "    texts, labels = inp['X'], inp['y']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      # Classifying\n",
    "      inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device)\n",
    "      output = model(**inputs)\n",
    "                  \n",
    "      pred_labels = torch.argmax(output.logits, 1)\n",
    "      \n",
    "      y_real.extend(labels.tolist())\n",
    "      y_pred.extend(pred_labels.tolist())\n",
    "\n",
    "  # Performance metrics\n",
    "  accuracy = accuracy_score(y_real, y_pred)*100\n",
    "\n",
    "  # Precision, recall, f1 scores\n",
    "  precision, recall, f1score, support = scores(y_real, y_pred, average='micro')\n",
    "\n",
    "  # Add metrics to evaluation list\n",
    "  evaluation_metrics_list.append(dict([\n",
    "      ('Model', 'BERTimbau'),\n",
    "      ('Accuracy (%)', round(accuracy, 2)),\n",
    "      ('Precision', round(precision, 2)),\n",
    "      ('Recall', round(recall, 2)),\n",
    "      ('F1', round(f1score, 2))\n",
    "  ]))\n",
    "\n",
    "  return evaluation_metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "best_loss = float('inf')\n",
    "avg_val_loss = 0\n",
    "all_losses = {'train_loss':[], 'val_loss':[]}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "  losses = []\n",
    "\n",
    "  pretrained_model.train()\n",
    "  \n",
    "  for batch_idx, inp in enumerate(traindata):\n",
    "    texts, labels = inp['X'], inp['y']\n",
    "\n",
    "    # Classifying\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device) # Tokenize\n",
    "    output = pretrained_model(**inputs, labels=labels.to(device))\n",
    "\n",
    "    pretrained_model.zero_grad() # Clear any previously calculated gradients\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = output.loss\n",
    "    losses.append(float(loss)) # Accumulate losses over all batches\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step() \n",
    "\n",
    "  print('Train Epoch: {}'.format(epoch))\n",
    "  avg_loss = round(sum(losses) / len(losses), 5)\n",
    "  avg_val_loss = evaluate_val(pretrained_model, valdata) # Evaluation validation dataset for this epoch\n",
    "  print(f'\\nTraining Loss: {avg_loss:.3f}')\n",
    "  print(f'\\nValidation Loss: {avg_val_loss:.3f}')\n",
    "  all_losses['train_loss'].append(avg_loss)\n",
    "  all_losses['val_loss'].append(avg_val_loss)\n",
    "\n",
    "  if avg_val_loss < best_loss:\n",
    "    torch.save(pretrained_model.state_dict(), 'saved_weights.pt') # Save best weights\n",
    "    best_loss = avg_val_loss\n",
    "    print('Saving best model...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Evaluation analysis <a class=\"anchor\" id=\"section_4_6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute on test dataset\n",
    "\n",
    "pretrained_model.load_state_dict(torch.load('saved_weights.pt'))\n",
    "\n",
    "# Load the best model weights \n",
    "evaluation_metrics = evaluate_test(pretrained_model, testdata)\n",
    "evaluation = pd.DataFrame(data=evaluation_metrics)\n",
    "evaluation.columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
    "evaluation = evaluation.sort_values(by='Accuracy', ascending=False)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('stigma': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4bb6a5a8d9de86797f248650fa8544a019a00d157c3095d36faee5c402c003b5"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
